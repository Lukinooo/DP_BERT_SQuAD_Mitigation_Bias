{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for bootstrapping evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from datasets import load_metric\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for number of iterations and number of selected items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_samples = 200\n",
    "# sample_size = 1000\n",
    "num_samples = 100\n",
    "sample_size = 800\n",
    "# sample_size = 500\n",
    "num_for_average_metrics = 1 # toto asi vyhodim - zle sa bude pisat\n",
    "# num_for_average_metrics = 5 # toto asi vyhodim - zle sa bude pisat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_for_sample(sample):\n",
    "    formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in zip(sample['id'], sample['prediction_text'])]\n",
    "    references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in sample]\n",
    "    return metric.compute(predictions=formatted_predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_log_files = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'squad_base'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('valid_pred_labeled_with_added_from_func.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = 'squad_super_distances_7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_supersampled_model = pd.read_json('./from_debiased_models/squad_supersampled_distances_7.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting of the data \n",
    "\n",
    "#### Based on distance of the closest word (from question) from the answer in context - items with distance lower or equal than 3 and items with distance higher than 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation of metrics for samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"metrics_for_specific_runs.csv\", \"w\") as file:\n",
    "#     file.write(f\"name,samples,sample_size,iters,field,threshold,type,exact_match_quantile_0.025,exact_match_quantile_0.975,exact_match_mean,f1_quantile_0.025,f1_quantile_0.975,f1_mean,len_lower,len_higher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"average_metrics_for_runs.csv\", \"w\") as file:\n",
    "#     file.write(f\"name,samples,sample_size,iters,field,threshold,type,exact_match_quantile_0.025,exact_match_quantile_0.975,exact_match_mean,f1_quantile_0.025,f1_quantile_0.975,f1_mean,len_lower,len_higher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"evaluated_metrics_for_average.csv\", \"w\") as file:\n",
    "#     file.write(f\"metric,samples,sample_size,iters,field,threshold,is_not_overlap,distance,len_lower,len_higher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"metrics_with_intervals_distances_for_dataset_comparison.csv\", \"w\") as file:\n",
    "#     file.write(f\"dataset,field,threshold,lower_interval_em,distance,higher_interval_em,lower_interval_f1,distance,higher_interval_f1,samples,sample_size,len_lower,len_higher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"data_for_violin.csv\", \"w\") as file:\n",
    "#     file.write(f\"dataset\\tfield\\tthreshold\\tlower_interval_em\\tdistance\\thigher_interval_em\\tlower_interval_f1\\tdistance\\thigher_interval_f1\\tsamples\\tsample_size\\tlen_lower\\tlen_higher\\tlower_em_list\\thigher_em_list\\tlower_f1_list\\thigher_f1_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_for_bunch(data):\n",
    "    exact_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    for i in tqdm(range(num_samples)):\n",
    "        df = data.sample(n=sample_size)\n",
    "        sample = Dataset.from_pandas(df)\n",
    "        metrics1 = compute_metrics_for_sample(sample)\n",
    "        exact_list.append(metrics1['exact_match'])\n",
    "        f1_list.append(metrics1['f1'])\n",
    "    \n",
    "    d = {'exact_match': exact_list, 'f1': f1_list}\n",
    "    df = pd.DataFrame(d)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_distance_between_intervals(lower_025, lower_975, higher_025, higher_975):\n",
    "    distance_between_intervals = 0\n",
    "    if lower_975 > higher_025 and lower_025 > higher_975:\n",
    "        distance_between_intervals = lower_025 - higher_975\n",
    "        return True, distance_between_intervals \n",
    "    elif higher_975 > lower_025 and higher_025 > lower_975:\n",
    "        distance_between_intervals = higher_025 - lower_975\n",
    "        return True, distance_between_intervals\n",
    "    else:\n",
    "        return False, distance_between_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def does_not_have_enought_samples(field, threshold, data_higher, data_lower):\n",
    "    if write_to_log_files:\n",
    "        with open(\"metrics_for_specific_runs.csv\", \"a\") as file_append:\n",
    "            file_append.write(f\"\\nlower_than_{threshold}_for_field_{field}_not_enough_samples,{num_samples},{sample_size},{num_for_average_metrics},{field},{threshold},lower,-1,-1,-1,-1,-1,-1,{len(data_lower)},{len(data_higher)}\")\n",
    "        with open(\"metrics_for_specific_runs.csv\", \"a\") as file_append:\n",
    "            file_append.write(f\"\\nhigher_than_{threshold}_for_field_{field}_not_enough_samples,{num_samples},{sample_size},{num_for_average_metrics},{field},{threshold},higher,-1,-1,-1,-1,-1,-1,{len(data_lower)},{len(data_higher)}\")\n",
    "        with open(\"average_metrics_for_runs.csv\", \"a\") as file_append:\n",
    "            file_append.write(f\"\\naverage_lower_than_{threshold}_for_field_{field}_not_enough_samples,{num_samples},{sample_size},{num_for_average_metrics},{field},{threshold},lower,-1,-1,-1,-1,-1,-1,{len(data_lower)},{len(data_higher)}\")\n",
    "            file_append.write(f\"\\naverage_higher_than_{threshold}_for_field_{field}_not_enough_samples,{num_samples},{sample_size},{num_for_average_metrics},{field},{threshold},higher,-1,-1,-1,-1,-1,-1,{len(data_lower)},{len(data_higher)}\")\n",
    "        with open(\"evaluated_metrics_for_average.csv\", \"a\") as file_append:\n",
    "            file_append.write(f\"\\nexact_match_not_enough_samples,{num_samples},{sample_size},{num_for_average_metrics},{field},{threshold},Nan,-1,{len(data_lower)},{len(data_higher)}\")\n",
    "            file_append.write(f\"\\nf1_not_enough_samples,{num_samples},{sample_size},{num_for_average_metrics},{field},{threshold},Nan,-1,{len(data_lower)},{len(data_higher)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "def compute_metrics_average_split(data, field, threshold):\n",
    "    data_higher, data_lower = [x for _, x in data.groupby(data[field] <= threshold)]\n",
    "\n",
    "    if len(data_higher) < sample_size or len(data_lower) < sample_size:\n",
    "        does_not_have_enought_samples(field, threshold, data_higher, data_lower)\n",
    "        return -1, -1\n",
    "\n",
    "    lower_exact_match_quantile_025 = []\n",
    "    lower_exact_match_quantile_975 = []\n",
    "    lower_exact_match_mean = []\n",
    "    lower_f1_quantile_025 = []\n",
    "    lower_f1_quantile_975 = []\n",
    "    lower_f1_mean = []\n",
    "    higher_exact_match_quantile_025 = []\n",
    "    higher_exact_match_quantile_975 = []\n",
    "    higher_exact_match_mean = []\n",
    "    higher_f1_quantile_025 = []\n",
    "    higher_f1_quantile_975 = []\n",
    "    higher_f1_mean = []\n",
    "    df_lower = []\n",
    "    df_higher = []\n",
    "\n",
    "\n",
    "    for i in tqdm(range(num_for_average_metrics)):\n",
    "        df_lower = compute_metrics_for_bunch(data_lower)\n",
    "        lower_exact_match_quantile_025.append(df_lower['exact_match'].quantile(0.025))\n",
    "        lower_exact_match_quantile_975.append(df_lower['exact_match'].quantile(0.975))\n",
    "        lower_exact_match_mean.append(df_lower['exact_match'].mean())\n",
    "        lower_f1_quantile_025.append(df_lower['f1'].quantile(0.025))\n",
    "        lower_f1_quantile_975.append(df_lower['f1'].quantile(0.975))\n",
    "        lower_f1_mean.append(df_lower['f1'].mean())\n",
    "\n",
    "        if write_to_log_files:\n",
    "            with open(\"metrics_for_specific_runs.csv\", \"a\") as file_append:\n",
    "                file_append.write(f\"\\nlower_than_{threshold}_for_field_{field},{num_samples},{sample_size},{num_for_average_metrics},{field},{threshold},lower,{df_lower['exact_match'].quantile(0.025)},{df_lower['exact_match'].quantile(0.975)},{df_lower['exact_match'].mean()},{df_lower['f1'].quantile(0.025)},{df_lower['f1'].quantile(0.975)},{df_lower['f1'].mean()},{len(data_lower)},{len(data_higher)}\")\n",
    "\n",
    "        df_higher = compute_metrics_for_bunch(data_higher)\n",
    "        higher_exact_match_quantile_025.append(df_higher['exact_match'].quantile(0.025))\n",
    "        higher_exact_match_quantile_975.append(df_higher['exact_match'].quantile(0.975))\n",
    "        higher_exact_match_mean.append(df_higher['exact_match'].mean())\n",
    "        higher_f1_quantile_025.append(df_higher['f1'].quantile(0.025))\n",
    "        higher_f1_quantile_975.append(df_higher['f1'].quantile(0.975))\n",
    "        higher_f1_mean.append(df_higher['f1'].mean())\n",
    "\n",
    "        if write_to_log_files:\n",
    "            with open(\"metrics_for_specific_runs.csv\", \"a\") as file_append:\n",
    "                file_append.write(f\"\\nhigher_than_{threshold}_for_field_{field},{num_samples},{sample_size},{num_for_average_metrics},{field},{threshold},higher,{df_higher['exact_match'].quantile(0.025)},{df_higher['exact_match'].quantile(0.975)},{df_higher['exact_match'].mean()},{df_higher['f1'].quantile(0.025)},{df_higher['f1'].quantile(0.975)},{df_higher['f1'].mean()},{len(data_lower)},{len(data_higher)}\")\n",
    "\n",
    "    if write_to_log_files:\n",
    "        with open(\"average_metrics_for_runs.csv\", \"a\") as file_append:\n",
    "            file_append.write(f\"\\naverage_lower_than_{threshold}_for_field_{field},{num_samples},{sample_size},{num_for_average_metrics},{field},{threshold},lower,{mean(lower_exact_match_quantile_025)},{mean(lower_exact_match_quantile_975)},{mean(lower_exact_match_mean)},{mean(lower_f1_quantile_025)},{mean(lower_f1_quantile_975)},{mean(lower_f1_mean)},{len(data_lower)},{len(data_higher)}\")\n",
    "            file_append.write(f\"\\naverage_higher_than_{threshold}_for_field_{field},{num_samples},{sample_size},{num_for_average_metrics},{field},{threshold},higher,{mean(higher_exact_match_quantile_025)},{mean(higher_exact_match_quantile_975)},{mean(higher_exact_match_mean)},{mean(higher_f1_quantile_025)},{mean(higher_f1_quantile_975)},{mean(higher_f1_mean)},{len(data_lower)},{len(data_higher)}\")\n",
    "\n",
    "    is_not_overlap_em, distance_em = find_the_distance_between_intervals(mean(lower_exact_match_quantile_025), mean(lower_exact_match_quantile_975), mean(higher_exact_match_quantile_025), mean(higher_exact_match_quantile_975))\n",
    "    is_not_overlap_f1, distance_f1 = find_the_distance_between_intervals(mean(lower_f1_quantile_025), mean(lower_f1_quantile_975), mean(higher_f1_quantile_025), mean(higher_f1_quantile_975))\n",
    "\n",
    "    if write_to_log_files:\n",
    "        with open(\"evaluated_metrics_for_average.csv\", \"a\") as file_append:\n",
    "            file_append.write(f\"\\nexact_match,{num_samples},{sample_size},{num_for_average_metrics},{field},{threshold},{is_not_overlap_em},{distance_em},{len(data_lower)},{len(data_higher)}\")\n",
    "            file_append.write(f\"\\nf1,{num_samples},{sample_size},{num_for_average_metrics},{field},{threshold},{is_not_overlap_f1},{distance_f1},{len(data_lower)},{len(data_higher)}\")\n",
    "\n",
    "    with open(\"metrics_with_intervals_distances_for_dataset_comparison.csv\", \"a\") as file_append:\n",
    "        file_append.write(f\"\\n{dataset},{field},{threshold},<{mean(lower_exact_match_quantile_025)};{mean(lower_exact_match_quantile_975)}>,{distance_em},<{mean(higher_exact_match_quantile_025)};{mean(higher_exact_match_quantile_975)}>,<{mean(lower_f1_quantile_025)};{mean(lower_f1_quantile_975)}>,{distance_f1},<{mean(higher_f1_quantile_025)};{mean(higher_f1_quantile_975)}>,{num_samples},{sample_size},{len(data_lower)},{len(data_higher)}\")\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        with open(\"data_for_violin.csv\", \"a\") as file_append:\n",
    "            file_append.write(f\"\\n{dataset}\\t{field}\\t{threshold}\\t<{mean(lower_exact_match_quantile_025)};{mean(lower_exact_match_quantile_975)}>\\t{distance_em}\\t<{mean(higher_exact_match_quantile_025)};{mean(higher_exact_match_quantile_975)}>\\t<{mean(lower_f1_quantile_025)};{mean(lower_f1_quantile_975)}>\\t{distance_f1}\\t<{mean(higher_f1_quantile_025)};{mean(higher_f1_quantile_975)}>\\t{num_samples}\\t{sample_size}\\t{len(data_lower)}\\t{len(data_higher)}\\t{df_lower['exact_match'][i]}\\tlower\\t{df_lower['f1'][i]}\\tlower\")\n",
    "            file_append.write(f\"\\n{dataset}\\t{field}\\t{threshold}\\t<{mean(lower_exact_match_quantile_025)};{mean(lower_exact_match_quantile_975)}>\\t{distance_em}\\t<{mean(higher_exact_match_quantile_025)};{mean(higher_exact_match_quantile_975)}>\\t<{mean(lower_f1_quantile_025)};{mean(lower_f1_quantile_975)}>\\t{distance_f1}\\t<{mean(higher_f1_quantile_025)};{mean(higher_f1_quantile_975)}>\\t{num_samples}\\t{sample_size}\\t{len(data_lower)}\\t{len(data_higher)}\\t{df_higher['exact_match'][i]}\\thigher\\t{df_higher['f1'][i]}\\thigher\")\n",
    "\n",
    "    print(f\"Average exact match with params: samples {sample_size} iters {num_samples} ---- are independent: {is_not_overlap_em} the distance is: {distance_em}\")\n",
    "\n",
    "    print(f\"Average f1 with params: samples {sample_size} iters {num_samples} ---- are independent: {is_not_overlap_f1} the distance is: {distance_f1}\")\n",
    "\n",
    "    return distance_em, distance_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_longest_distance(data, field, low_bound, upp_bound):\n",
    "    index_em = 0\n",
    "    index_f1 = 0\n",
    "    max_em_distance = 0\n",
    "    max_f1_distance = 0\n",
    "\n",
    "    distance_em = 0\n",
    "    distance_f1 = 0\n",
    "\n",
    "    for i in tqdm(range(low_bound, upp_bound, 1)):\n",
    "        distance_em, distance_f1 = compute_metrics_average_split(data, field, i)\n",
    "        if distance_em > max_em_distance:\n",
    "            max_em_distance = distance_em\n",
    "            index_em = i\n",
    "        if distance_f1 > max_f1_distance:\n",
    "            max_f1_distance = distance_f1\n",
    "            index_f1 = i\n",
    "\n",
    "    print(f\"The biggest distance between exact match intervals was with threshold {index_em} and the distance was {max_em_distance}.\")\n",
    "    print(f\"The biggest distance between f1 intervals was with threshold {index_f1} and the distance was {max_f1_distance}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24696ea0ccd4e219b1d31fd53677269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc62e8b5f05840e7a70118c17a5e62df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59293e75367e4fc2a014345eadad1e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b90cbc89e34b8ebd5d7b981b02f933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average exact match with params: samples 800 iters 100 ---- are independent: True the distance is: 8.803125000000009\n",
      "Average f1 with params: samples 800 iters 100 ---- are independent: True the distance is: 8.320067159352774\n",
      "The biggest distance between exact match intervals was with threshold 7 and the distance was 8.803125000000009.\n",
      "The biggest distance between f1 intervals was with threshold 7 and the distance was 8.320067159352774.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a10d660e0b24190bd0873452269abbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54bb93379e534316b7f158a4dbcfa3ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f8af7bc6748465f8de4714eb55952ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f8bed10b1d4b4f9bc7f3e438d2d1fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average exact match with params: samples 800 iters 100 ---- are independent: True the distance is: 0.171875\n",
      "Average f1 with params: samples 800 iters 100 ---- are independent: False the distance is: 0\n",
      "The biggest distance between exact match intervals was with threshold 4 and the distance was 0.171875.\n",
      "The biggest distance between f1 intervals was with threshold 0 and the distance was 0.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e29886cfcb4d6b906f1a630e2aada1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b8b0df9903457fae5e644d825bf2de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8106e147c29e42dc964fb4805375ef1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c6ca536abc48b3ac2fab667e6ccea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average exact match with params: samples 800 iters 100 ---- are independent: True the distance is: 8.684375000000003\n",
      "Average f1 with params: samples 800 iters 100 ---- are independent: True the distance is: 1.4462761160935287\n",
      "The biggest distance between exact match intervals was with threshold 3 and the distance was 8.684375000000003.\n",
      "The biggest distance between f1 intervals was with threshold 3 and the distance was 1.4462761160935287.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b316f128274351aaf3867c628170d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528d307767a54394ba58ce19397de7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7d59e7dd924fdaab4b35103b0aa2a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average exact match with params: samples 800 iters 100 ---- are independent: True the distance is: 2.559375000000003\n",
      "Average f1 with params: samples 800 iters 100 ---- are independent: True the distance is: 2.1884230907556343\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2573a44086f74b179b8bb5839b3d486a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e67d52b95a4cc49d6bb21be0356fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6ebdd17aaf4df8bf867e860ff291a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a87b5d409cf44a4b7d114ea3e36fa1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average exact match with params: samples 800 iters 100 ---- are independent: False the distance is: 0\n",
      "Average f1 with params: samples 800 iters 100 ---- are independent: False the distance is: 0\n",
      "The biggest distance between exact match intervals was with threshold 0 and the distance was 0.\n",
      "The biggest distance between f1 intervals was with threshold 0 and the distance was 0.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e4084ddea0a4ff68e789febf36f4982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9ef82ff02c4e0eb5157b28f7e192f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2bb9099f1154020983b67d3b93ed599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbec981868a341bf8ea64a3d7f3f8a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average exact match with params: samples 800 iters 100 ---- are independent: True the distance is: 2.2375000000000114\n",
      "Average f1 with params: samples 800 iters 100 ---- are independent: True the distance is: 1.3933506893193055\n",
      "The biggest distance between exact match intervals was with threshold 0 and the distance was 2.2375000000000114.\n",
      "The biggest distance between f1 intervals was with threshold 0 and the distance was 1.3933506893193055.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831be913a39c482dab9dc4d37f768067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f104612657140e8954343f767cf4a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe7caa7977744a09d79aaaef9b71f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4045db103a54729961cc16a4e2fa70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average exact match with params: samples 800 iters 100 ---- are independent: True the distance is: 0.8031250000000085\n",
      "Average f1 with params: samples 800 iters 100 ---- are independent: True the distance is: 0.39578747090899924\n",
      "The biggest distance between exact match intervals was with threshold 1 and the distance was 0.8031250000000085.\n",
      "The biggest distance between f1 intervals was with threshold 1 and the distance was 0.39578747090899924.\n"
     ]
    }
   ],
   "source": [
    "find_longest_distance(data[data.distances >= 0], 'distances', 7, 8)\n",
    "find_longest_distance(data, 'similar_words', 4, 5)\n",
    "find_longest_distance(data, 'answer_lenght', 3, 4)\n",
    "compute_metrics_average_split(data, 'cosine_similarity', 0.10)\n",
    "find_longest_distance(data, 'kth_sentence', 0, 1)\n",
    "find_longest_distance(data, 'max_sim_ents', 0, 1)\n",
    "find_longest_distance(data[data.answer_subject_positions >= 0], 'answer_subject_positions', 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'squad_distances_v2'\n",
    "data_supersampled_model = pd.read_json('./from_debiased_models/enhanced_squad_supersampled_distances_7_v2.json')\n",
    "for i in range(3): #one more run\n",
    "    find_longest_distance(data_supersampled_model[data_supersampled_model.distances >= 0], 'distances', 2, 9)\n",
    "    find_longest_distance(data_supersampled_model, 'similar_words', 3, 9)\n",
    "    find_longest_distance(data_supersampled_model, 'answer_lenght', 1, 6)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.10)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.20)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.30)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.40)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.50)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.60)\n",
    "    find_longest_distance(data_supersampled_model, 'max_sim_ents', 0, 5)\n",
    "    find_longest_distance(data_supersampled_model[data_supersampled_model.answer_subject_positions >= 0], 'answer_subject_positions', 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enhanced_squad_base_v2\n",
    "\n",
    "dataset = 'squad_base_v2'\n",
    "data_supersampled_model = pd.read_json('./from_debiased_models/enhanced_squad_base_v2.json')\n",
    "for i in range(3): #one more run\n",
    "    find_longest_distance(data_supersampled_model[data_supersampled_model.distances >= 0], 'distances', 2, 9)\n",
    "    find_longest_distance(data_supersampled_model, 'similar_words', 3, 9)\n",
    "    find_longest_distance(data_supersampled_model, 'answer_lenght', 1, 6)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.10)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.20)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.30)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.40)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.50)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.60)\n",
    "    find_longest_distance(data_supersampled_model, 'max_sim_ents', 0, 5)\n",
    "    find_longest_distance(data_supersampled_model[data_supersampled_model.answer_subject_positions >= 0], 'answer_subject_positions', 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_longest_distance(data[data.distances >= 0], 'distances', 7, 8)\n",
    "find_longest_distance(data, 'similar_words', 4, 5)\n",
    "find_longest_distance(data, 'answer_lenght', 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 450\n",
    "find_longest_distance(data, 'kth_sentence', 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_average_split(data, 'cosine_similarity', 0.10)\n",
    "compute_metrics_average_split(data, 'cosine_similarity', 0.20)\n",
    "compute_metrics_average_split(data, 'cosine_similarity', 0.30)\n",
    "compute_metrics_average_split(data, 'cosine_similarity', 0.40)\n",
    "compute_metrics_average_split(data, 'cosine_similarity', 0.50)\n",
    "compute_metrics_average_split(data, 'cosine_similarity', 0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 450\n",
    "compute_metrics_average_split(data, 'cosine_similarity', 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_longest_distance(data[data.answer_subject_positions >= 0], 'answer_subject_positions', 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_longest_distance(data, 'max_sim_ents', 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_longest_distance(data, 'question_length', 5, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'squad_super_all_th_2'\n",
    "data_supersampled_model = pd.read_json('./from_debiased_models/enhanced_squad_supersampled_all_th_2.json')\n",
    "for i in range(3): #one more run\n",
    "    find_longest_distance(data_supersampled_model[data_supersampled_model.distances >= 0], 'distances', 2, 9)\n",
    "    find_longest_distance(data_supersampled_model, 'similar_words', 3, 9)\n",
    "    find_longest_distance(data_supersampled_model, 'answer_lenght', 1, 6)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.10)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.20)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.30)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.40)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.50)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.60)\n",
    "    find_longest_distance(data_supersampled_model, 'max_sim_ents', 0, 5)\n",
    "    find_longest_distance(data_supersampled_model[data_supersampled_model.answer_subject_positions >= 0], 'answer_subject_positions', 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'squad_super_all_v1'\n",
    "data_supersampled_model = pd.read_json('./from_debiased_models/enhanced_squad_supersampled_all_v1.json')\n",
    "for i in range(3):\n",
    "    find_longest_distance(data_supersampled_model[data_supersampled_model.distances >= 0], 'distances', 2, 9)\n",
    "    find_longest_distance(data_supersampled_model, 'similar_words', 3, 9)\n",
    "    find_longest_distance(data_supersampled_model, 'answer_lenght', 1, 6)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.10)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.20)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.30)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.40)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.50)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.60)\n",
    "    find_longest_distance(data_supersampled_model, 'max_sim_ents', 0, 5)\n",
    "    find_longest_distance(data_supersampled_model[data_supersampled_model.answer_subject_positions >= 0], 'answer_subject_positions', 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'squad_super_all_v2'\n",
    "data_supersampled_model = pd.read_json('./from_debiased_models/enhanced_squad_supersampled_all_v2.json')\n",
    "for i in range(3):\n",
    "    find_longest_distance(data_supersampled_model[data_supersampled_model.distances >= 0], 'distances', 2, 9)\n",
    "    find_longest_distance(data_supersampled_model, 'similar_words', 3, 9)\n",
    "    find_longest_distance(data_supersampled_model, 'answer_lenght', 1, 6)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.10)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.20)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.30)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.40)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.50)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.60)\n",
    "    find_longest_distance(data_supersampled_model, 'max_sim_ents', 0, 5)\n",
    "    find_longest_distance(data_supersampled_model[data_supersampled_model.answer_subject_positions >= 0], 'answer_subject_positions', 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'squad_super_all_dd_ns'\n",
    "data_supersampled_model = pd.read_json('./from_debiased_models/enhanced_squad_supersampled_all_dd_ns.json')\n",
    "for i in range(3):\n",
    "    find_longest_distance(data_supersampled_model[data_supersampled_model.distances >= 0], 'distances', 2, 9)\n",
    "    find_longest_distance(data_supersampled_model, 'similar_words', 3, 9)\n",
    "    find_longest_distance(data_supersampled_model, 'answer_lenght', 1, 6)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.10)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.20)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.30)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.40)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.50)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.60)\n",
    "    find_longest_distance(data_supersampled_model, 'max_sim_ents', 0, 5)\n",
    "    find_longest_distance(data_supersampled_model[data_supersampled_model.answer_subject_positions >= 0], 'answer_subject_positions', 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'squad_base'\n",
    "data = data = pd.read_json('valid_pred_labeled_with_added_from_func.json')\n",
    "for i in range(3):\n",
    "    find_longest_distance(data[data.distances >= 0], 'distances', 2, 9)\n",
    "    find_longest_distance(data, 'similar_words', 3, 9)\n",
    "    find_longest_distance(data, 'answer_lenght', 1, 6)\n",
    "    compute_metrics_average_split(data, 'cosine_similarity', 0.10)\n",
    "    compute_metrics_average_split(data, 'cosine_similarity', 0.20)\n",
    "    compute_metrics_average_split(data, 'cosine_similarity', 0.30)\n",
    "    compute_metrics_average_split(data, 'cosine_similarity', 0.40)\n",
    "    compute_metrics_average_split(data, 'cosine_similarity', 0.50)\n",
    "    compute_metrics_average_split(data, 'cosine_similarity', 0.60)\n",
    "    find_longest_distance(data, 'max_sim_ents', 0, 5)\n",
    "    find_longest_distance(data[data.answer_subject_positions >= 0], 'answer_subject_positions', 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'squad_super_cosine_similarity_01'\n",
    "data_supersampled_model = pd.read_json('./from_debiased_models/enhanced_squad_supersampled_cosine_similarity_01.json')\n",
    "for i in range(3):\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.10)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.20)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.30)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.40)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.50)\n",
    "    compute_metrics_average_split(data_supersampled_model, 'cosine_similarity', 0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'squad_super_max_sim_ents_0'\n",
    "data_supersampled_model = pd.read_json('./from_debiased_models/enhanced_squad_supersampled_similar_entities_0.json')\n",
    "for i in range(3):\n",
    "    find_longest_distance(data_supersampled_model, 'max_sim_ents', 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'squad_super_ans_sub_pos_1'\n",
    "data_supersampled_model = pd.read_json('./from_debiased_models/enhanced_squad_supersampled_ans_sub_pos_1.json')\n",
    "for i in range(3):\n",
    "    find_longest_distance(data_supersampled_model[data_supersampled_model.answer_subject_positions >= 0], 'answer_subject_positions', 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'squad_base'\n",
    "data = pd.read_json('valid_pred_labeled_with_added_from_func.json')\n",
    "for i in range(4):\n",
    "    find_longest_distance(data[data.distances >= 0], 'distances', 2, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'squad_super_distances_7'\n",
    "data_supersampled_model = pd.read_json('./from_debiased_models/enhanced_squad_supersampled_distances_7.json')\n",
    "for i in range(4):\n",
    "    find_longest_distance(data_supersampled_model[data_supersampled_model.distances >= 0], 'distances', 2, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'squad_base'\n",
    "data = pd.read_json('valid_pred_labeled_with_added_from_func.json')\n",
    "for i in range(5):\n",
    "    find_longest_distance(data, 'similar_words', 3, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'squad_super_similar_words_4'\n",
    "data_supersampled_model = pd.read_json('./from_debiased_models/enhanced_squad_supersampled_similar_words_4.json')\n",
    "for i in range(5):\n",
    "    find_longest_distance(data_supersampled_model, 'similar_words', 3, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'squad_base'\n",
    "data = pd.read_json('valid_pred_labeled_with_added_from_func.json')\n",
    "for i in range(5):\n",
    "    find_longest_distance(data, 'answer_lenght', 1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'squad_super_answer_length_3'\n",
    "data_supersampled_model = pd.read_json('./from_debiased_models/enhanced_squad_supersampled_answer_length_3.json')\n",
    "for i in range(5):\n",
    "    find_longest_distance(data_supersampled_model, 'answer_lenght', 1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_longest_distance(data[data.distances_new >= 0], 'distances_new', 2, 7)\n",
    "find_longest_distance(data[data.distances_new >= 0], 'distances_new', 7, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_longest_distance(data[data.distances >= 0], 'distances', 2, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_longest_distance(data, 'kth_sentence_new', 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[data.answer_subject_positions >= 0]\n",
    "find_longest_distance(data[data.answer_subject_positions >= 0], 'answer_subject_positions', 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.answer_subject_positions >= 0]\n",
    "find_longest_distance(data, 'answer_subject_positions', 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.answer_subject_positions >= 0]\n",
    "find_longest_distance(data, 'answer_subject_positions', 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[data.subject_in_context_count >= 0]\n",
    "find_longest_distance(data[data.subject_in_context_count >= 0], 'subject_in_context_count', 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_longest_distance(data, 'max_sim_ents', 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_longest_distance(data, 'max_sim_ents', 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_longest_distance(data, 'subject_in_context_count', 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_longest_distance(data, 'answer_subject_positions', 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_longest_distance(data, 'answer_subject_positions', 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_longest_distance(data, 'distances_new', 2, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_longest_distance(data, 'distances', 2, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['distances'] == -1, 'distances'] = 1000\n",
    "data['distances'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_longest_distance(data, 'distances', 2, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_longest_distance(data, 'answer_lenght', 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in range(200, 1100, 100):\n",
    "    sample_size = size\n",
    "    for iters in range(100, 600, 100):\n",
    "        num_samples = iters\n",
    "        find_longest_distance(data, 'distances', 2, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in range(900, 1100, 100):\n",
    "    sample_size = size\n",
    "    for iters in range(100, 600, 100):\n",
    "        num_samples = iters\n",
    "        find_longest_distance(data, 'distances', 2, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in range(200, 1100, 100):\n",
    "    sample_size = size\n",
    "    for iters in range(100, 600, 100):\n",
    "        num_samples = iters\n",
    "        find_longest_distance(data, 'similar_words', 3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in range(200, 1100, 200):\n",
    "    sample_size = size\n",
    "    for iters in range(100, 600, 200):\n",
    "        num_samples = iters\n",
    "        find_longest_distance(data, 'kth_sentence', 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in range(200, 1100, 200):\n",
    "    sample_size = size\n",
    "    for iters in range(100, 600, 200):\n",
    "        num_samples = iters\n",
    "        compute_metrics_average_split(data, 'cosine_similarity', 0.10)\n",
    "        compute_metrics_average_split(data, 'cosine_similarity', 0.20)\n",
    "        compute_metrics_average_split(data, 'cosine_similarity', 0.30)\n",
    "        compute_metrics_average_split(data, 'cosine_similarity', 0.40)\n",
    "        compute_metrics_average_split(data, 'cosine_similarity', 0.50)\n",
    "        compute_metrics_average_split(data, 'cosine_similarity', 0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_longest_distance(data, 'distances', 2, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_longest_distance(data, 'similar_words', 3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_longest_distance(data, 'similar_words', 2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_longest_distance(data, 'kth_sentence', 0, 5) #zvacsit interval, skusit pre vacsie k\n",
    "# find_longest_distance(data, 'kth_sentence', 5, 8) #zvacsit interval, skusit pre vacsie k\n",
    "# find_longest_distance(data, 'kth_sentence', 1, 5) #zvacsit interval, skusit pre vacsie k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 200\n",
    "sample_size = 1000\n",
    "\n",
    "find_longest_distance(data, 'kth_sentence', 4, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_average_split(data, 'cosine_similarity', 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_average_split(data, 'cosine_similarity', 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_average_split(data, 'cosine_similarity', 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_average_split(data, 'cosine_similarity', 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_average_split(data, 'cosine_similarity', 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_average_split(data, 'cosine_similarity', 0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_average_split(data, 'cosine_similarity', 0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_average_split(data, 'cosine_similarity', 0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_average_split(data, 'cosine_similarity', 0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_average_split(data, 'cosine_similarity', 0.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_average_split(data, 'distances', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_average_split(data, 'distances', 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_em = 0\n",
    "index_f1 = 0\n",
    "max_em_distance = 0\n",
    "max_f1_distance = 0\n",
    "\n",
    "distance_em = 0\n",
    "distance_f1 = 0\n",
    "\n",
    "for i in range(3, 6, 1):\n",
    "    distance_em, distance_f1 = compute_metrics_average_split(data, 'similar_words', i)\n",
    "    if distance_em > max_em_distance:\n",
    "        max_em_distance = distance_em\n",
    "        index_em = i\n",
    "    if distance_f1 > max_f1_distance:\n",
    "        max_f1_distance = distance_f1\n",
    "        index_f1 = i\n",
    "\n",
    "print(f\"The biggest distance between exact match intervals was with threshold {index_em} and the distance was {max_em_distance}.\")\n",
    "print(f\"The biggest distance between f1 intervals was with threshold {index_f1} and the distance was {max_f1_distance}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_average_split(data, 'similar_words', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_average_split(data, 'distances', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_average_split(data, 'similar_words', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_average_split(data, 'kth_sentence', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_average_split(data, 'kth_sentence', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_average_split(data, 'kth_sentence', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_average_split(data, 'cosine_similarity', 0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_average_split(data, 'cosine_similarity', 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_average_split(data, 'cosine_similarity', 0.45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Older segments of code, now used in functions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_distances = data[data.distances >= 0]\n",
    "data_higher, data_lower = [x for _, x in data.groupby(data_distances['distances'] <= 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_list_lower = []\n",
    "f1_list_lower = []\n",
    "\n",
    "for i in tqdm(range(num_samples)):\n",
    "    df = data_lower.sample(n=sample_size)\n",
    "    sample = Dataset.from_pandas(df)\n",
    "    metrics1 = compute_metrics_for_sample(sample)\n",
    "    exact_list_lower.append(metrics1['exact_match'])\n",
    "    f1_list_lower.append(metrics1['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_lower = {'exact_match': exact_list_lower, 'f1': f1_list_lower}\n",
    "d_lower\n",
    "lower_than_4 = pd.DataFrame(d_lower)\n",
    "lower_than_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_list_higher = []\n",
    "f1_list_higher = []\n",
    "\n",
    "for i in tqdm(range(num_samples)):\n",
    "    df = data_higher.sample(n=sample_size)\n",
    "    sample = Dataset.from_pandas(df)\n",
    "    metrics1 = compute_metrics_for_sample(sample)\n",
    "    exact_list_higher.append(metrics1['exact_match'])\n",
    "    f1_list_higher.append(metrics1['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_higher = {'exact_match': exact_list_higher, 'f1': f1_list_higher}\n",
    "d_higher\n",
    "higher_than_4 = pd.DataFrame(d_higher)\n",
    "higher_than_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_than_4.quantile([0.025, 0.975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "higher_than_4.quantile([0.025, 0.975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_than_4.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "higher_than_4.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting of the data\n",
    "\n",
    "#### Based on count of the similar words between question and context - lower or equal to 4 and higher than 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_similar_words_higher, data_similar_words_lower = [x for _, x in data.groupby(data['similar_words'] <= 4)]\n",
    "print('Higher count data len: ', len(data_similar_words_higher))\n",
    "print('Lower count data len: ', len(data_similar_words_lower))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation of metrics for samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_list_similar_words_lower = []\n",
    "f1_list_similar_words_lower = []\n",
    "\n",
    "for i in tqdm(range(num_samples)):\n",
    "    df = data_similar_words_lower.sample(n=sample_size)\n",
    "    sample = Dataset.from_pandas(df)\n",
    "    metrics1 = compute_metrics_for_sample(sample)\n",
    "    exact_list_similar_words_lower.append(metrics1['exact_match'])\n",
    "    f1_list_similar_words_lower.append(metrics1['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_similar_words_lower = {'exact_match': exact_list_similar_words_lower, 'f1': f1_list_similar_words_lower}\n",
    "d_similar_words_lower\n",
    "lower_similar_words_than_4 = pd.DataFrame(d_similar_words_lower)\n",
    "lower_similar_words_than_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_list_similar_words_higher = []\n",
    "f1_list_similar_words_higher = []\n",
    "\n",
    "for i in tqdm(range(num_samples)):\n",
    "    df = data_similar_words_higher.sample(n=sample_size)\n",
    "    sample = Dataset.from_pandas(df)\n",
    "    metrics1 = compute_metrics_for_sample(sample)\n",
    "    exact_list_similar_words_higher.append(metrics1['exact_match'])\n",
    "    f1_list_similar_words_higher.append(metrics1['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_similar_words_higher = {'exact_match': exact_list_similar_words_higher, 'f1': f1_list_similar_words_higher}\n",
    "d_similar_words_higher\n",
    "higher_similar_words_than_4 = pd.DataFrame(d_similar_words_higher)\n",
    "higher_similar_words_than_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_similar_words_than_4.quantile([0.025, 0.975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "higher_similar_words_than_4.quantile([0.025, 0.975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_similar_words_than_4.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "higher_similar_words_than_4.describe()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7a7a7019c9e0c1b9f0e0c3be70dc9924c7adf8b61dfc45d9a6a9f2f7a665204"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
