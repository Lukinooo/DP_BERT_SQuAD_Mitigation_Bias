{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Functions and parts of the code taken from Jupyter notebook from HuggingFace GitHub https://github.com/huggingface/notebooks/blob/main/examples/question_answering.ipynb"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-04-30T23:02:00.309198Z","iopub.status.busy":"2022-04-30T23:02:00.308665Z","iopub.status.idle":"2022-04-30T23:02:12.842122Z","shell.execute_reply":"2022-04-30T23:02:12.841195Z","shell.execute_reply.started":"2022-04-30T23:02:00.309102Z"},"trusted":true},"outputs":[],"source":["! pip install datasets transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T23:02:12.844922Z","iopub.status.busy":"2022-04-30T23:02:12.844343Z","iopub.status.idle":"2022-04-30T23:02:20.047172Z","shell.execute_reply":"2022-04-30T23:02:20.046415Z","shell.execute_reply.started":"2022-04-30T23:02:12.844841Z"},"trusted":true},"outputs":[],"source":["import transformers\n","from datasets import load_dataset, load_metric\n","from datasets import Dataset\n","from transformers import AutoTokenizer\n","from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n","from transformers import EarlyStoppingCallback\n","from transformers import default_data_collator\n","import shutil\n","import pandas as pd\n","\n","print(transformers.__version__)\n","model_checkpoint = \"bert-base-uncased\"\n","batch_size = 16\n","squad_v2 = False\n","max_length = 384 # The maximum length of a feature (question and context)\n","doc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T23:02:20.050022Z","iopub.status.busy":"2022-04-30T23:02:20.048321Z","iopub.status.idle":"2022-04-30T23:02:33.776109Z","shell.execute_reply":"2022-04-30T23:02:33.775418Z","shell.execute_reply.started":"2022-04-30T23:02:20.049934Z"},"trusted":true},"outputs":[],"source":["datasets = load_dataset(\"squad_v2\" if squad_v2 else \"squad\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T23:02:33.779036Z","iopub.status.busy":"2022-04-30T23:02:33.778347Z","iopub.status.idle":"2022-04-30T23:02:36.810198Z","shell.execute_reply":"2022-04-30T23:02:36.809453Z","shell.execute_reply.started":"2022-04-30T23:02:33.778997Z"},"trusted":true},"outputs":[],"source":["# train SQuAD with computed heuristics\n","# file path may need some tweeks based on the location\n","data = pd.read_json('../input/squad-train-supersampled-all-heuristics/squad_train_with_heuristics_flags.json')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T23:02:36.811714Z","iopub.status.busy":"2022-04-30T23:02:36.811462Z","iopub.status.idle":"2022-04-30T23:02:36.818688Z","shell.execute_reply":"2022-04-30T23:02:36.818034Z","shell.execute_reply.started":"2022-04-30T23:02:36.811681Z"},"trusted":true},"outputs":[],"source":["def supersample_dataset(data_lower, data_higher):\n","    \"\"\"Super-sample the training dataset\n","    balances the size of two subsets obtained by split on threshold for specific heuristic\n","\n","    Args:\n","        data_lower (Pandas Dataframe): dataset split with values lower or equal than the threshold\n","        data_higher (Pandas Dataframe): dataset split with values higher than the threshold\n","    \n","    Returns:\n","        Pandas Dataframe: super-sampled training dataset\n","    \"\"\"\n","    list_subsets = []\n","    list_subsets.append(data_lower)\n","    list_subsets.append(data_higher)\n","\n","    if len(data_higher) > len(data_lower):\n","        for i in range(len(data_higher)//len(data_lower)):\n","#             print(f\"higher {i}\")\n","            list_subsets.append(data_lower.sample(frac=1))\n","        new_data = pd.concat(list_subsets)\n","    else:\n","        for i in range(len(data_lower)//len(data_higher)):\n","#             print(f\"lower {i}\")\n","            list_subsets.append(data_higher.sample(frac=1))\n","        new_data = pd.concat(list_subsets)\n","    \n","    return new_data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T23:02:36.820605Z","iopub.status.busy":"2022-04-30T23:02:36.820137Z","iopub.status.idle":"2022-04-30T23:02:43.701354Z","shell.execute_reply":"2022-04-30T23:02:43.700577Z","shell.execute_reply.started":"2022-04-30T23:02:36.820542Z"},"trusted":true},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T23:02:43.702923Z","iopub.status.busy":"2022-04-30T23:02:43.702627Z","iopub.status.idle":"2022-04-30T23:02:43.707442Z","shell.execute_reply":"2022-04-30T23:02:43.706534Z","shell.execute_reply.started":"2022-04-30T23:02:43.702874Z"},"trusted":true},"outputs":[],"source":["pad_on_right = tokenizer.padding_side == \"right\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T23:02:43.709822Z","iopub.status.busy":"2022-04-30T23:02:43.709087Z","iopub.status.idle":"2022-04-30T23:02:43.726475Z","shell.execute_reply":"2022-04-30T23:02:43.725736Z","shell.execute_reply.started":"2022-04-30T23:02:43.709769Z"},"trusted":true},"outputs":[],"source":["# function from HuggingFace GitHub\n","# with original comments\n","def prepare_train_features(examples):\n","    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n","    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n","    # left whitespace\n","    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n","\n","    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n","    # in one example possible giving several features when a context is long, each of those features having a\n","    # context that overlaps a bit the context of the previous feature.\n","    tokenized_examples = tokenizer(\n","        examples[\"question\" if pad_on_right else \"context\"],\n","        examples[\"context\" if pad_on_right else \"question\"],\n","        truncation=\"only_second\" if pad_on_right else \"only_first\",\n","        max_length=max_length,\n","        stride=doc_stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","    # Since one example might give us several features if it has a long context, we need a map from a feature to\n","    # its corresponding example. This key gives us just that.\n","    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n","    # The offset mappings will give us a map from token to character position in the original context. This will\n","    # help us compute the start_positions and end_positions.\n","    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n","\n","    # Let's label those examples!\n","    tokenized_examples[\"start_positions\"] = []\n","    tokenized_examples[\"end_positions\"] = []\n","\n","    for i, offsets in enumerate(offset_mapping):\n","        # We will label impossible answers with the index of the CLS token.\n","        input_ids = tokenized_examples[\"input_ids\"][i]\n","        cls_index = input_ids.index(tokenizer.cls_token_id)\n","\n","        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n","        sequence_ids = tokenized_examples.sequence_ids(i)\n","\n","        # One example can give several spans, this is the index of the example containing this span of text.\n","        sample_index = sample_mapping[i]\n","        answers = examples[\"answers\"][sample_index]\n","        # If no answers are given, set the cls_index as answer.\n","        if len(answers[\"answer_start\"]) == 0:\n","            tokenized_examples[\"start_positions\"].append(cls_index)\n","            tokenized_examples[\"end_positions\"].append(cls_index)\n","        else:\n","            # Start/end character index of the answer in the text.\n","            start_char = answers[\"answer_start\"][0]\n","            end_char = start_char + len(answers[\"text\"][0])\n","\n","            # Start token index of the current span in the text.\n","            token_start_index = 0\n","            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n","                token_start_index += 1\n","\n","            # End token index of the current span in the text.\n","            token_end_index = len(input_ids) - 1\n","            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n","                token_end_index -= 1\n","\n","            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n","            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n","                tokenized_examples[\"start_positions\"].append(cls_index)\n","                tokenized_examples[\"end_positions\"].append(cls_index)\n","            else:\n","                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n","                # Note: we could go after the last offset if the answer is the last word (edge case).\n","                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n","                    token_start_index += 1\n","                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n","                while offsets[token_end_index][1] >= end_char:\n","                    token_end_index -= 1\n","                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n","\n","    return tokenized_examples"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T23:02:43.730480Z","iopub.status.busy":"2022-04-30T23:02:43.729425Z","iopub.status.idle":"2022-04-30T23:02:43.739487Z","shell.execute_reply":"2022-04-30T23:02:43.738600Z","shell.execute_reply.started":"2022-04-30T23:02:43.730449Z"},"trusted":true},"outputs":[],"source":["# import for Kaggle logging problem\n","import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T23:02:43.742956Z","iopub.status.busy":"2022-04-30T23:02:43.742098Z","iopub.status.idle":"2022-04-30T23:02:43.768319Z","shell.execute_reply":"2022-04-30T23:02:43.767535Z","shell.execute_reply.started":"2022-04-30T23:02:43.742919Z"},"trusted":true},"outputs":[],"source":["def training(training_type, type_):\n","    \"\"\"Dataset split, preprocessing and model fine-tuning\n","\n","    Args:\n","        training_type (str): name of the heuristic for the dataset split and super-sampling\n","        type_ (str): suffix for fine-tuned model\n","    \"\"\"\n","    \n","    # split of dataset based on the training_type argument\n","    if training_type == 'base':\n","        new_data = data\n","    elif training_type == 'distance':\n","        data_higher, data_lower = [x for _, x in data.groupby(data['distances'] <= 7)]\n","        new_data = supersample_dataset(data_lower, data_higher)\n","    elif training_type == 'similar':\n","        data_higher, data_lower = [x for _, x in data.groupby(data['similar_words'] <= 4)]\n","        new_data = supersample_dataset(data_lower, data_higher)\n","    elif training_type == 'cosine':\n","        data_higher, data_lower = [x for _, x in data.groupby(data['cosine_similarity'] <= 0.1)]\n","        new_data = supersample_dataset(data_lower, data_higher)\n","    elif training_type == 'answer':\n","        data_higher, data_lower = [x for _, x in data.groupby(data['answer_lenght'] <= 3)]\n","        new_data = supersample_dataset(data_lower, data_higher)\n","    elif training_type == 'entities':\n","        data_higher, data_lower = [x for _, x in data.groupby(data['max_sim_ents'] <= 0)]\n","        new_data = supersample_dataset(data_lower, data_higher)\n","    elif training_type == 'position':\n","        data_higher, data_lower = [x for _, x in data.groupby(data['answer_subject_positions'] <= 1)]\n","        new_data = supersample_dataset(data_lower, data_higher)\n","    elif training_type == 'all':\n","        new_data = pd.concat([data.query('dist_flag == 0 and sim_flag == 0 and ans_flag == 0 and cos_flag == 0 and pos_flag == 0 and ents_flag == 0'),\n","                            data.query('dist_flag == 1'),\n","                            data.query('sim_flag == 1'),\n","                            data.query('ans_flag == 1'),\n","                            data.query('cos_flag == 1'),\n","                            data.query('pos_flag == 1'),\n","                            data.query('ents_flag == 1')]).sample(frac=1)\n","    elif training_type == 'top_3':\n","        new_data = pd.concat([data,\n","                        data.query('ans_flag == 1'),\n","                        data.query('cos_flag == 1'),\n","                        data.query('cos_flag == 1'),\n","                        data.query('cos_flag == 1'),\n","                        data.query('dist_flag == 1'),\n","                        data.query('dist_flag == 1')]).sample(frac=1)\n","    elif training_type == 'dist_cos':\n","        new_data = pd.concat([data,\n","                        data.query('cos_flag == 1'),\n","                        data.query('cos_flag == 1'),\n","                        data.query('cos_flag == 1'),\n","                        data.query('cos_flag == 1'),\n","                        data.query('dist_flag == 1'),\n","                        data.query('dist_flag == 1'),\n","                        data.query('dist_flag == 1')]).sample(frac=1)\n","    elif training_type == 'dist_ans':\n","        new_data = pd.concat([data,\n","                        data.query('ans_flag == 1'),\n","                        data.query('dist_flag == 1'),\n","                        data.query('dist_flag == 1'),\n","                        data.query('dist_flag == 1')]).sample(frac=1)\n","    elif training_type == 'ans_cos':\n","        new_data = pd.concat([data,\n","                        data.query('ans_flag == 1'),\n","                        data.query('cos_flag == 1'),\n","                        data.query('cos_flag == 1'),\n","                        data.query('cos_flag == 1'),\n","                        data.query('cos_flag == 1')]).sample(frac=1)\n","    else:\n","        print('something went wrong! wrong type.')\n","\n","    # removal of redundant columns\n","    if training_type != 'base':\n","        new_data = new_data.drop(['distances', 'similar_words', 'answer_lenght', 'cosine_similarity', 'answer_subject_positions', 'max_sim_ents', 'dist_flag', 'sim_flag', 'ans_flag', 'cos_flag', 'pos_flag', 'ents_flag'], axis = 1)\n","        datasets['train'] = Dataset.from_pandas(new_data)\n","        datasets['train'] = datasets['train'].remove_columns(\"__index_level_0__\")\n","    \n","    # data preprocessing\n","    tokenized_datasets = datasets.map(prepare_train_features, batched=True, remove_columns=datasets[\"train\"].column_names)\n","    model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n","\n","    # Training arguments\n","    model_name = model_checkpoint.split(\"/\")[-1]\n","    args = TrainingArguments(\n","        f\"{model_name}-finetuned-squad_with_callbacks\",\n","        evaluation_strategy = \"steps\",\n","        eval_steps = 200, # Evaluation and Save happens every 200 steps\n","        save_steps = 200,\n","        logging_steps = 200,\n","        save_total_limit = 5, # Only last 5 models are saved. Older ones are deleted.\n","        learning_rate=2e-5,\n","        per_device_train_batch_size=batch_size,\n","        per_device_eval_batch_size=batch_size,\n","        num_train_epochs=3,\n","        weight_decay=0.01,\n","        report_to=\"none\",\n","        load_best_model_at_end=True,\n","    )\n","\n","    data_collator = default_data_collator\n","\n","    # Trainer for \n","    trainer = Trainer(\n","        model,\n","        args,\n","        train_dataset=tokenized_datasets[\"train\"],\n","        eval_dataset=tokenized_datasets[\"validation\"],\n","        data_collator=data_collator,\n","        tokenizer=tokenizer,    \n","        callbacks = [EarlyStoppingCallback(early_stopping_patience=10)]\n","    )\n","\n","    trainer.train()\n","\n","    trainer.save_model(\"test-squad-trained\")\n","\n","    # save model to zip\n","    shutil.make_archive(f\"{model_name}-finetuned-squad_with_callbacks_{type_}\", 'zip', './test-squad-trained')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-30T23:02:43.770209Z","iopub.status.busy":"2022-04-30T23:02:43.769747Z","iopub.status.idle":"2022-05-01T04:23:53.864852Z","shell.execute_reply":"2022-05-01T04:23:53.862548Z","shell.execute_reply.started":"2022-04-30T23:02:43.770170Z"},"trusted":true},"outputs":[],"source":["# all possible heuristics and combinations supported to super-sampled the data and fine-tune BERT\n","# you can choose what you want\n","#--------------------------------\n","\n","training_types = []\n","types_ = []\n","\n","# training_types.append('base')\n","# types_.append('base')\n","\n","# training_types.append('distance')\n","# types_.append('supersampled_distances_7')\n","\n","# training_types.append('similar')\n","# types_.append('supersampled_similar_4')\n","\n","# training_types.append('cosine')\n","# types_.append('supersampled_cosine_01')\n","\n","# training_types.append('answer')\n","# types_.append('supersampled_answer_3')\n","\n","# training_types.append('entities')\n","# types_.append('supersampled_entities_0')\n","\n","# training_types.append('position')\n","# types_.append('supersampled_position_1')\n","\n","# training_types.append('all')\n","# types_.append('supersampled_all')\n","\n","# training_types.append('top_3')\n","# types_.append('supersampled_top_3')\n","\n","# training_types.append('dist_cos')\n","# types_.append('supersampled_dist_cos')\n","\n","# training_types.append('dist_ans')\n","# types_.append('supersampled_dist_ans')\n","\n","# training_types.append('ans_cos')\n","# types_.append('supersampled_ans_cos')\n","\n","for training_type, type_ in zip(training_types, types_):\n","    print(f\"{training_type}, {type_}\")\n","    training(training_type, type_)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
