{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing of other validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load predictions and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/luki/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/luki/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.auto import tqdm\n",
    "from nltk import tokenize\n",
    "import spacy\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_dataset = 'nq_dev_formated.json'\n",
    "# validation_dataset = 'adversarialQA_validation.json'\n",
    "# validation_dataset = 'valid_pred_labeled.json'\n",
    "# file_folder = './'\n",
    "file_folder = './from_debiased_models/'\n",
    "# validation_dataset = 'squad_supersampled_similar_words_4.json'\n",
    "# validation_dataset = 'squad_supersampled_answer_length_3.json'\n",
    "# validation_dataset = 'squad_supersampled_distances_7.json'\n",
    "\n",
    "# validation_dataset = 'squad_supersampled_all_v1.json'\n",
    "# validation_dataset = 'squad_supersampled_all_v2.json'\n",
    "# validation_dataset = 'squad_supersampled_all_dd_ns.json'\n",
    "# validation_dataset = 'squad_supersampled_ans_sub_pos_1.json'\n",
    "# validation_dataset = 'squad_supersampled_cosine_similarity_01.json'\n",
    "validation_dataset = 'squad_supersampled_similar_entities_0.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count similar words between question and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(file_folder + validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>prediction_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>56be4db0acb8001400a502ec</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team represented the AFC at Super Bo...</td>\n",
       "      <td>{'text': ['Denver Broncos', 'Denver Broncos', ...</td>\n",
       "      <td>Denver Broncos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>56be4db0acb8001400a502ed</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team represented the NFC at Super Bo...</td>\n",
       "      <td>{'text': ['Carolina Panthers', 'Carolina Panth...</td>\n",
       "      <td>Carolina Panthers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>56be4db0acb8001400a502ee</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Where did Super Bowl 50 take place?</td>\n",
       "      <td>{'text': ['Santa Clara, California', 'Levi's S...</td>\n",
       "      <td>Santa Clara, California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>56be4db0acb8001400a502ef</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team won Super Bowl 50?</td>\n",
       "      <td>{'text': ['Denver Broncos', 'Denver Broncos', ...</td>\n",
       "      <td>Denver Broncos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>56be4db0acb8001400a502f0</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>What color was used to emphasize the 50th anni...</td>\n",
       "      <td>{'text': ['gold', 'gold', 'gold'], 'answer_sta...</td>\n",
       "      <td>gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10565</th>\n",
       "      <td>10565</td>\n",
       "      <td>5737aafd1c456719005744fb</td>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What is the metric term less used than the New...</td>\n",
       "      <td>{'text': ['kilogram-force', 'pound-force', 'ki...</td>\n",
       "      <td>pound-force</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10566</th>\n",
       "      <td>10566</td>\n",
       "      <td>5737aafd1c456719005744fc</td>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What is the kilogram-force sometimes reffered ...</td>\n",
       "      <td>{'text': ['kilopond', 'kilopond', 'kilopond', ...</td>\n",
       "      <td>kilopond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10567</th>\n",
       "      <td>10567</td>\n",
       "      <td>5737aafd1c456719005744fd</td>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What is a very seldom used unit of mass in the...</td>\n",
       "      <td>{'text': ['slug', 'metric slug', 'metric slug'...</td>\n",
       "      <td>the metric slug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10568</th>\n",
       "      <td>10568</td>\n",
       "      <td>5737aafd1c456719005744fe</td>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What seldom used term of a unit of force equal...</td>\n",
       "      <td>{'text': ['kip', 'kip', 'kip', 'kip', 'kip'], ...</td>\n",
       "      <td>alternate, but rarely used unit of mass: the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10569</th>\n",
       "      <td>10569</td>\n",
       "      <td>5737aafd1c456719005744ff</td>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What is the seldom used force unit equal to on...</td>\n",
       "      <td>{'text': ['sthène', 'sthène', 'sthène', 'sthèn...</td>\n",
       "      <td>the metric slug</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10570 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                        id          title  \\\n",
       "0          0  56be4db0acb8001400a502ec  Super_Bowl_50   \n",
       "1          1  56be4db0acb8001400a502ed  Super_Bowl_50   \n",
       "2          2  56be4db0acb8001400a502ee  Super_Bowl_50   \n",
       "3          3  56be4db0acb8001400a502ef  Super_Bowl_50   \n",
       "4          4  56be4db0acb8001400a502f0  Super_Bowl_50   \n",
       "...      ...                       ...            ...   \n",
       "10565  10565  5737aafd1c456719005744fb          Force   \n",
       "10566  10566  5737aafd1c456719005744fc          Force   \n",
       "10567  10567  5737aafd1c456719005744fd          Force   \n",
       "10568  10568  5737aafd1c456719005744fe          Force   \n",
       "10569  10569  5737aafd1c456719005744ff          Force   \n",
       "\n",
       "                                                 context  \\\n",
       "0      Super Bowl 50 was an American football game to...   \n",
       "1      Super Bowl 50 was an American football game to...   \n",
       "2      Super Bowl 50 was an American football game to...   \n",
       "3      Super Bowl 50 was an American football game to...   \n",
       "4      Super Bowl 50 was an American football game to...   \n",
       "...                                                  ...   \n",
       "10565  The pound-force has a metric counterpart, less...   \n",
       "10566  The pound-force has a metric counterpart, less...   \n",
       "10567  The pound-force has a metric counterpart, less...   \n",
       "10568  The pound-force has a metric counterpart, less...   \n",
       "10569  The pound-force has a metric counterpart, less...   \n",
       "\n",
       "                                                question  \\\n",
       "0      Which NFL team represented the AFC at Super Bo...   \n",
       "1      Which NFL team represented the NFC at Super Bo...   \n",
       "2                    Where did Super Bowl 50 take place?   \n",
       "3                      Which NFL team won Super Bowl 50?   \n",
       "4      What color was used to emphasize the 50th anni...   \n",
       "...                                                  ...   \n",
       "10565  What is the metric term less used than the New...   \n",
       "10566  What is the kilogram-force sometimes reffered ...   \n",
       "10567  What is a very seldom used unit of mass in the...   \n",
       "10568  What seldom used term of a unit of force equal...   \n",
       "10569  What is the seldom used force unit equal to on...   \n",
       "\n",
       "                                                 answers  \\\n",
       "0      {'text': ['Denver Broncos', 'Denver Broncos', ...   \n",
       "1      {'text': ['Carolina Panthers', 'Carolina Panth...   \n",
       "2      {'text': ['Santa Clara, California', 'Levi's S...   \n",
       "3      {'text': ['Denver Broncos', 'Denver Broncos', ...   \n",
       "4      {'text': ['gold', 'gold', 'gold'], 'answer_sta...   \n",
       "...                                                  ...   \n",
       "10565  {'text': ['kilogram-force', 'pound-force', 'ki...   \n",
       "10566  {'text': ['kilopond', 'kilopond', 'kilopond', ...   \n",
       "10567  {'text': ['slug', 'metric slug', 'metric slug'...   \n",
       "10568  {'text': ['kip', 'kip', 'kip', 'kip', 'kip'], ...   \n",
       "10569  {'text': ['sthène', 'sthène', 'sthène', 'sthèn...   \n",
       "\n",
       "                                         prediction_text  \n",
       "0                                         Denver Broncos  \n",
       "1                                      Carolina Panthers  \n",
       "2                                Santa Clara, California  \n",
       "3                                         Denver Broncos  \n",
       "4                                                   gold  \n",
       "...                                                  ...  \n",
       "10565                                        pound-force  \n",
       "10566                                           kilopond  \n",
       "10567                                    the metric slug  \n",
       "10568  alternate, but rarely used unit of mass: the m...  \n",
       "10569                                    the metric slug  \n",
       "\n",
       "[10570 rows x 7 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reset_index()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_similar_words_in_question_and_context(data):\n",
    "\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "    similar_words = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        context1 = nltk.word_tokenize(data['context'][i])\n",
    "        question1 = nltk.word_tokenize(data['question'][i])\n",
    "        context_new = [word for word in context1 if word.isalnum()]\n",
    "        question_new = [word for word in question1 if word.isalnum()]\n",
    "        similar_words.append(len(set(context_new).intersection(set(question_new))))\n",
    "        \n",
    "    return similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>prediction_text</th>\n",
       "      <th>similar_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>56be4db0acb8001400a502ec</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team represented the AFC at Super Bo...</td>\n",
       "      <td>{'text': ['Denver Broncos', 'Denver Broncos', ...</td>\n",
       "      <td>Denver Broncos</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>56be4db0acb8001400a502ed</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team represented the NFC at Super Bo...</td>\n",
       "      <td>{'text': ['Carolina Panthers', 'Carolina Panth...</td>\n",
       "      <td>Carolina Panthers</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>56be4db0acb8001400a502ee</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Where did Super Bowl 50 take place?</td>\n",
       "      <td>{'text': ['Santa Clara, California', 'Levi's S...</td>\n",
       "      <td>Santa Clara, California</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>56be4db0acb8001400a502ef</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>Which NFL team won Super Bowl 50?</td>\n",
       "      <td>{'text': ['Denver Broncos', 'Denver Broncos', ...</td>\n",
       "      <td>Denver Broncos</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>56be4db0acb8001400a502f0</td>\n",
       "      <td>Super_Bowl_50</td>\n",
       "      <td>Super Bowl 50 was an American football game to...</td>\n",
       "      <td>What color was used to emphasize the 50th anni...</td>\n",
       "      <td>{'text': ['gold', 'gold', 'gold'], 'answer_sta...</td>\n",
       "      <td>gold</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10565</th>\n",
       "      <td>10565</td>\n",
       "      <td>5737aafd1c456719005744fb</td>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What is the metric term less used than the New...</td>\n",
       "      <td>{'text': ['kilogram-force', 'pound-force', 'ki...</td>\n",
       "      <td>pound-force</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10566</th>\n",
       "      <td>10566</td>\n",
       "      <td>5737aafd1c456719005744fc</td>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What is the kilogram-force sometimes reffered ...</td>\n",
       "      <td>{'text': ['kilopond', 'kilopond', 'kilopond', ...</td>\n",
       "      <td>kilopond</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10567</th>\n",
       "      <td>10567</td>\n",
       "      <td>5737aafd1c456719005744fd</td>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What is a very seldom used unit of mass in the...</td>\n",
       "      <td>{'text': ['slug', 'metric slug', 'metric slug'...</td>\n",
       "      <td>the metric slug</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10568</th>\n",
       "      <td>10568</td>\n",
       "      <td>5737aafd1c456719005744fe</td>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What seldom used term of a unit of force equal...</td>\n",
       "      <td>{'text': ['kip', 'kip', 'kip', 'kip', 'kip'], ...</td>\n",
       "      <td>alternate, but rarely used unit of mass: the m...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10569</th>\n",
       "      <td>10569</td>\n",
       "      <td>5737aafd1c456719005744ff</td>\n",
       "      <td>Force</td>\n",
       "      <td>The pound-force has a metric counterpart, less...</td>\n",
       "      <td>What is the seldom used force unit equal to on...</td>\n",
       "      <td>{'text': ['sthène', 'sthène', 'sthène', 'sthèn...</td>\n",
       "      <td>the metric slug</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10570 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                        id          title  \\\n",
       "0          0  56be4db0acb8001400a502ec  Super_Bowl_50   \n",
       "1          1  56be4db0acb8001400a502ed  Super_Bowl_50   \n",
       "2          2  56be4db0acb8001400a502ee  Super_Bowl_50   \n",
       "3          3  56be4db0acb8001400a502ef  Super_Bowl_50   \n",
       "4          4  56be4db0acb8001400a502f0  Super_Bowl_50   \n",
       "...      ...                       ...            ...   \n",
       "10565  10565  5737aafd1c456719005744fb          Force   \n",
       "10566  10566  5737aafd1c456719005744fc          Force   \n",
       "10567  10567  5737aafd1c456719005744fd          Force   \n",
       "10568  10568  5737aafd1c456719005744fe          Force   \n",
       "10569  10569  5737aafd1c456719005744ff          Force   \n",
       "\n",
       "                                                 context  \\\n",
       "0      Super Bowl 50 was an American football game to...   \n",
       "1      Super Bowl 50 was an American football game to...   \n",
       "2      Super Bowl 50 was an American football game to...   \n",
       "3      Super Bowl 50 was an American football game to...   \n",
       "4      Super Bowl 50 was an American football game to...   \n",
       "...                                                  ...   \n",
       "10565  The pound-force has a metric counterpart, less...   \n",
       "10566  The pound-force has a metric counterpart, less...   \n",
       "10567  The pound-force has a metric counterpart, less...   \n",
       "10568  The pound-force has a metric counterpart, less...   \n",
       "10569  The pound-force has a metric counterpart, less...   \n",
       "\n",
       "                                                question  \\\n",
       "0      Which NFL team represented the AFC at Super Bo...   \n",
       "1      Which NFL team represented the NFC at Super Bo...   \n",
       "2                    Where did Super Bowl 50 take place?   \n",
       "3                      Which NFL team won Super Bowl 50?   \n",
       "4      What color was used to emphasize the 50th anni...   \n",
       "...                                                  ...   \n",
       "10565  What is the metric term less used than the New...   \n",
       "10566  What is the kilogram-force sometimes reffered ...   \n",
       "10567  What is a very seldom used unit of mass in the...   \n",
       "10568  What seldom used term of a unit of force equal...   \n",
       "10569  What is the seldom used force unit equal to on...   \n",
       "\n",
       "                                                 answers  \\\n",
       "0      {'text': ['Denver Broncos', 'Denver Broncos', ...   \n",
       "1      {'text': ['Carolina Panthers', 'Carolina Panth...   \n",
       "2      {'text': ['Santa Clara, California', 'Levi's S...   \n",
       "3      {'text': ['Denver Broncos', 'Denver Broncos', ...   \n",
       "4      {'text': ['gold', 'gold', 'gold'], 'answer_sta...   \n",
       "...                                                  ...   \n",
       "10565  {'text': ['kilogram-force', 'pound-force', 'ki...   \n",
       "10566  {'text': ['kilopond', 'kilopond', 'kilopond', ...   \n",
       "10567  {'text': ['slug', 'metric slug', 'metric slug'...   \n",
       "10568  {'text': ['kip', 'kip', 'kip', 'kip', 'kip'], ...   \n",
       "10569  {'text': ['sthène', 'sthène', 'sthène', 'sthèn...   \n",
       "\n",
       "                                         prediction_text  similar_words  \n",
       "0                                         Denver Broncos              7  \n",
       "1                                      Carolina Panthers              7  \n",
       "2                                Santa Clara, California              3  \n",
       "3                                         Denver Broncos              4  \n",
       "4                                                   gold              8  \n",
       "...                                                  ...            ...  \n",
       "10565                                        pound-force              6  \n",
       "10566                                           kilopond              5  \n",
       "10567                                    the metric slug              9  \n",
       "10568  alternate, but rarely used unit of mass: the m...              7  \n",
       "10569                                    the metric slug              7  \n",
       "\n",
       "[10570 rows x 8 columns]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['similar_words'] = count_similar_words_in_question_and_context(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10570.000000\n",
       "mean         6.047020\n",
       "std          2.813025\n",
       "min          0.000000\n",
       "25%          4.000000\n",
       "50%          6.000000\n",
       "75%          8.000000\n",
       "max         28.000000\n",
       "Name: similar_words, dtype: float64"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['similar_words'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5     1635\n",
       "6     1529\n",
       "4     1387\n",
       "7     1295\n",
       "3     1084\n",
       "8      998\n",
       "9      699\n",
       "2      554\n",
       "10     431\n",
       "11     280\n",
       "1      222\n",
       "12     163\n",
       "13     110\n",
       "14      61\n",
       "0       34\n",
       "15      29\n",
       "16      26\n",
       "17      14\n",
       "19       6\n",
       "18       5\n",
       "20       3\n",
       "21       2\n",
       "28       1\n",
       "22       1\n",
       "23       1\n",
       "Name: similar_words, dtype: int64"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['similar_words'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_json('enhanced_'+validation_dataset, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count distance of the closest question word from answer in context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_json('enhanced_'+validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from this web site https://www.codegrepper.com/code-examples/python/find+index+of+sublist+in+list+python\n",
    "def find_sub_list(sl,l):\n",
    "    results=[]\n",
    "    sll=len(sl)\n",
    "    for ind in (i for i,e in enumerate(l) if e==sl[0]):\n",
    "        if l[ind:ind+sll]==sl:\n",
    "            results.append((ind,ind+sll-1))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/luki/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def count_lowest_position_of_word_from_question_in_context(data):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    distances = []\n",
    "    words = []\n",
    "\n",
    "    for i in range(len(data)):        \n",
    "        indexes_of_words = []\n",
    "        context_list = tokenizer.tokenize(data['context'][i])\n",
    "        question_list = tokenizer.tokenize(data['question'][i])\n",
    "        answer_text = tokenizer.tokenize(data['answers'][i]['text'][0])\n",
    "        answer_start = data['answers'][i]['answer_start']\n",
    "\n",
    "        indexes_of_words = find_sub_list(answer_text, context_list)\n",
    "\n",
    "        if len(indexes_of_words) > 0:\n",
    "            answer_index = indexes_of_words[0][0]\n",
    "        else:\n",
    "            distances.append(-1)\n",
    "            words.append('None')\n",
    "            continue\n",
    "\n",
    "        filtered_words = [word for word in question_list if word not in stopwords.words('english')]\n",
    "\n",
    "        list_indexes = {}\n",
    "\n",
    "        for word in filtered_words:\n",
    "            if word in context_list:\n",
    "                for j in range(len(context_list)):\n",
    "                    if word == context_list[j]:\n",
    "                        list_indexes[abs(j - answer_index)] = context_list[j]\n",
    "\n",
    "        sort_orders = sorted(list_indexes.items(), key=lambda x: x[0], reverse=False)\n",
    "\n",
    "        if len(sort_orders) == 0:\n",
    "            distances.append(-1)\n",
    "            words.append('None')\n",
    "        else:\n",
    "            distances.append(sort_orders[0][0])\n",
    "            words.append(sort_orders[0][1])\n",
    "\n",
    "    return distances, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['str_answers'] = data['answers'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['distances'], data['closest_words'] = count_lowest_position_of_word_from_question_in_context(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2      2478\n",
       "1      2243\n",
       "3      1404\n",
       "4       886\n",
       "5       617\n",
       "       ... \n",
       "84        1\n",
       "108       1\n",
       "276       1\n",
       "85        1\n",
       "127       1\n",
       "Name: distances, Length: 98, dtype: int64"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['distances'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_json('enhanced_'+validation_dataset, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify in which sentence the answer is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_json('enhanced_'+validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "\n",
    "def identify_in_which_sentence_answer_is(data):\n",
    "    sentence_indexes = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        context1 = tokenize.sent_tokenize(data['context'][i])\n",
    "        answer = data['answers'][i]['text'][0]\n",
    "        nth = 0\n",
    "        for sentence in context1:\n",
    "            if answer in sentence:\n",
    "                break\n",
    "            nth += 1\n",
    "\n",
    "        sentence_indexes.append(nth)\n",
    "\n",
    "    return sentence_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['kth_sentence'] = identify_in_which_sentence_answer_is(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10570.000000\n",
       "mean         1.643992\n",
       "std          1.884932\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          1.000000\n",
       "75%          3.000000\n",
       "max         29.000000\n",
       "Name: kth_sentence, dtype: float64"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['kth_sentence'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10570.000000\n",
       "mean         1.643992\n",
       "std          1.884932\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          1.000000\n",
       "75%          3.000000\n",
       "max         29.000000\n",
       "Name: kth_sentence, dtype: float64"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['kth_sentence'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3571\n",
       "1     2511\n",
       "2     1790\n",
       "3     1262\n",
       "4      679\n",
       "5      336\n",
       "6      191\n",
       "7      109\n",
       "8       65\n",
       "9       21\n",
       "10      10\n",
       "11       5\n",
       "13       4\n",
       "15       4\n",
       "12       4\n",
       "29       2\n",
       "14       2\n",
       "16       2\n",
       "26       1\n",
       "27       1\n",
       "Name: kth_sentence, dtype: int64"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['kth_sentence'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3571\n",
       "1     2511\n",
       "2     1790\n",
       "3     1262\n",
       "4      679\n",
       "5      336\n",
       "6      191\n",
       "7      109\n",
       "8       65\n",
       "9       21\n",
       "10      10\n",
       "11       5\n",
       "13       4\n",
       "15       4\n",
       "12       4\n",
       "29       2\n",
       "14       2\n",
       "16       2\n",
       "26       1\n",
       "27       1\n",
       "Name: kth_sentence, dtype: int64"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['kth_sentence'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_json('enhanced_'+validation_dataset, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing cosine similarity from tf-idf between contexts and questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_json('enhanced_'+validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_json('./train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>{'text': ['a copper statue of Christ'], 'answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>{'text': ['the Main Building'], 'answer_start'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>{'text': ['a Marian place of prayer and reflec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>{'text': ['a golden statue of the Virgin Mary'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87594</th>\n",
       "      <td>5735d259012e2f140011a09d</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>In what US state did Kathmandu first establish...</td>\n",
       "      <td>{'text': ['Oregon'], 'answer_start': [229]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87595</th>\n",
       "      <td>5735d259012e2f140011a09e</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>What was Yangon previously known as?</td>\n",
       "      <td>{'text': ['Rangoon'], 'answer_start': [414]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87596</th>\n",
       "      <td>5735d259012e2f140011a09f</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>With what Belorussian city does Kathmandu have...</td>\n",
       "      <td>{'text': ['Minsk'], 'answer_start': [476]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87597</th>\n",
       "      <td>5735d259012e2f140011a0a0</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>In what year did Kathmandu create its initial ...</td>\n",
       "      <td>{'text': ['1975'], 'answer_start': [199]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87598</th>\n",
       "      <td>5735d259012e2f140011a0a1</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>What is KMC an initialism of?</td>\n",
       "      <td>{'text': ['Kathmandu Metropolitan City'], 'ans...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87599 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id                     title  \\\n",
       "0      5733be284776f41900661182  University_of_Notre_Dame   \n",
       "1      5733be284776f4190066117f  University_of_Notre_Dame   \n",
       "2      5733be284776f41900661180  University_of_Notre_Dame   \n",
       "3      5733be284776f41900661181  University_of_Notre_Dame   \n",
       "4      5733be284776f4190066117e  University_of_Notre_Dame   \n",
       "...                         ...                       ...   \n",
       "87594  5735d259012e2f140011a09d                 Kathmandu   \n",
       "87595  5735d259012e2f140011a09e                 Kathmandu   \n",
       "87596  5735d259012e2f140011a09f                 Kathmandu   \n",
       "87597  5735d259012e2f140011a0a0                 Kathmandu   \n",
       "87598  5735d259012e2f140011a0a1                 Kathmandu   \n",
       "\n",
       "                                                 context  \\\n",
       "0      Architecturally, the school has a Catholic cha...   \n",
       "1      Architecturally, the school has a Catholic cha...   \n",
       "2      Architecturally, the school has a Catholic cha...   \n",
       "3      Architecturally, the school has a Catholic cha...   \n",
       "4      Architecturally, the school has a Catholic cha...   \n",
       "...                                                  ...   \n",
       "87594  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87595  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87596  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87597  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87598  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "\n",
       "                                                question  \\\n",
       "0      To whom did the Virgin Mary allegedly appear i...   \n",
       "1      What is in front of the Notre Dame Main Building?   \n",
       "2      The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                      What is the Grotto at Notre Dame?   \n",
       "4      What sits on top of the Main Building at Notre...   \n",
       "...                                                  ...   \n",
       "87594  In what US state did Kathmandu first establish...   \n",
       "87595               What was Yangon previously known as?   \n",
       "87596  With what Belorussian city does Kathmandu have...   \n",
       "87597  In what year did Kathmandu create its initial ...   \n",
       "87598                      What is KMC an initialism of?   \n",
       "\n",
       "                                                 answers  \n",
       "0      {'text': ['Saint Bernadette Soubirous'], 'answ...  \n",
       "1      {'text': ['a copper statue of Christ'], 'answe...  \n",
       "2      {'text': ['the Main Building'], 'answer_start'...  \n",
       "3      {'text': ['a Marian place of prayer and reflec...  \n",
       "4      {'text': ['a golden statue of the Virgin Mary'...  \n",
       "...                                                  ...  \n",
       "87594        {'text': ['Oregon'], 'answer_start': [229]}  \n",
       "87595       {'text': ['Rangoon'], 'answer_start': [414]}  \n",
       "87596         {'text': ['Minsk'], 'answer_start': [476]}  \n",
       "87597          {'text': ['1975'], 'answer_start': [199]}  \n",
       "87598  {'text': ['Kathmandu Metropolitan City'], 'ans...  \n",
       "\n",
       "[87599 rows x 5 columns]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', use_idf=True)\n",
    "model = vectorizer.fit(train_dataset['context']) # fit na vsetkych datach\n",
    "\n",
    "def compute_similarity_between_context_and_question(data):\n",
    "    similarities = []\n",
    "\n",
    "    for i in tqdm(range(len(data))):\n",
    "        context1 = vectorizer.transform([data['context'][i]])\n",
    "        question1 = vectorizer.transform([data['question'][i]])\n",
    "        similarities.append(cosine_similarity(context1, question1)[0][0])\n",
    "\n",
    "    return similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec4f3eb8e3d49e08a1b72c47962aa72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['cosine_similarity'] = compute_similarity_between_context_and_question(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10570.000000\n",
       "mean         0.306264\n",
       "std          0.158483\n",
       "min          0.000000\n",
       "25%          0.187675\n",
       "50%          0.296845\n",
       "75%          0.418278\n",
       "max          0.910359\n",
       "Name: cosine_similarity, dtype: float64"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cosine_similarity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10570.000000\n",
       "mean         0.306264\n",
       "std          0.158483\n",
       "min          0.000000\n",
       "25%          0.187675\n",
       "50%          0.296845\n",
       "75%          0.418278\n",
       "max          0.910359\n",
       "Name: cosine_similarity, dtype: float64"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cosine_similarity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_json('enhanced_'+validation_dataset, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_distances = data[data.distances >= 0]\n",
    "data_higher, data_lower = [x for _, x in data.groupby(data_distances['distances'] <= 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract length of the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_json('enhanced_'+validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_answer_length(data):\n",
    "    answers_text = []\n",
    "    for i in range(len(data)):\n",
    "        answers_text.append(data['answers'][i]['text'])\n",
    "    answers_text\n",
    "\n",
    "    answer_lenght = []\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    for i in range(len(data)):\n",
    "        avg_lenght = 0\n",
    "        for j in range(len(answers_text[i])):\n",
    "            avg_lenght += len(tokenizer.tokenize(answers_text[i][j]))\n",
    "        av = avg_lenght/(len(answers_text[i]))\n",
    "        answer_lenght.append(av)\n",
    "\n",
    "    return answer_lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['answer_lenght'] = average_answer_length(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10570.000000\n",
       "mean         3.008505\n",
       "std          2.457632\n",
       "min          0.800000\n",
       "25%          1.333333\n",
       "50%          2.000000\n",
       "75%          3.666667\n",
       "max         24.333333\n",
       "Name: answer_lenght, dtype: float64"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['answer_lenght'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.000000     2294\n",
       "2.000000     1842\n",
       "3.000000     1016\n",
       "1.666667      516\n",
       "2.333333      470\n",
       "             ... \n",
       "14.800000       1\n",
       "18.666667       1\n",
       "22.333333       1\n",
       "17.666667       1\n",
       "13.600000       1\n",
       "Name: answer_lenght, Length: 164, dtype: int64"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['answer_lenght'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_json('enhanced_'+validation_dataset, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract number of similar NER to answer from context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_json('enhanced_'+validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ents(doc): \n",
    "    entities = []\n",
    "    if doc.ents: \n",
    "        for ent in doc.ents: \n",
    "            entities.append(ent.label_)\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_similar_NER_from_context_to_answer(data):\n",
    "    context_ents = []\n",
    "    answer_ents = []\n",
    "\n",
    "    for row in range(len(data)):\n",
    "        context = nlp(data['context'][row])\n",
    "        context_ents.append(show_ents(context))\n",
    "        for ans in data['answers'][row]['text']:\n",
    "            act_ans_ents_ = []\n",
    "            act_ans = nlp(ans)\n",
    "            act_ans_ents_.append(show_ents(act_ans))\n",
    "        answer_ents.append(act_ans_ents_)\n",
    "\n",
    "    max_sim_ents = []\n",
    "\n",
    "    for row, cont in zip(answer_ents, context_ents):\n",
    "        max = 0\n",
    "        for items in row:\n",
    "            for item in items:\n",
    "                if cont.count(item) > max:\n",
    "                    max = cont.count(item)\n",
    "        max_sim_ents.append(max)\n",
    "    \n",
    "    return max_sim_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['max_sim_ents'] = count_similar_NER_from_context_to_answer(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     5006\n",
       "1     1015\n",
       "2     1005\n",
       "3      817\n",
       "4      620\n",
       "5      531\n",
       "6      370\n",
       "7      299\n",
       "8      241\n",
       "9      148\n",
       "10      80\n",
       "12      69\n",
       "15      69\n",
       "11      67\n",
       "13      52\n",
       "19      34\n",
       "17      26\n",
       "16      22\n",
       "14      17\n",
       "22      14\n",
       "20      12\n",
       "26      11\n",
       "31      10\n",
       "18       8\n",
       "33       6\n",
       "25       6\n",
       "44       4\n",
       "21       3\n",
       "23       3\n",
       "27       3\n",
       "29       2\n",
       "Name: max_sim_ents, dtype: int64"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['max_sim_ents'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_json('enhanced_'+validation_dataset, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract number of occurencies of subject from question in context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data = pd.read_json('enhanced_'+validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_pieces(doc):\n",
    "    subjects = []\n",
    "    for ent in doc:\n",
    "        if ent.dep_ == 'nsubj':\n",
    "            subjects.append(ent.text)\n",
    "    return subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_subjects = []\n",
    "\n",
    "for item in data['question']:\n",
    "    question = nlp(item)\n",
    "    q_subjects.append(doc_pieces(question))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_in_context_count = []\n",
    "\n",
    "for context, q_sub in zip(data['context'], q_subjects):\n",
    "    context_with_no_punct = context.translate(str.maketrans('', '', string.punctuation))\n",
    "    # print(context_with_no_punct)\n",
    "    count = 0\n",
    "    max = 0\n",
    "    for item in q_sub:\n",
    "        if item in context_with_no_punct:\n",
    "            # print(f'Index {context_with_no_punct.index(item)}\\nWord {item}\\nCotext {context_with_no_punct}')\n",
    "            \n",
    "            indexes = [m.start() for m in re.finditer(item, context_with_no_punct)]\n",
    "            count = len(indexes)\n",
    "            if max < count:\n",
    "                max = count\n",
    "    subject_in_context_count.append(max)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 10,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 10,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 14,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 18,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 12,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 12,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 10,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_in_context_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10570"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subject_in_context_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['subject_in_context_count'] = subject_in_context_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4595\n",
       "1     2514\n",
       "2     1330\n",
       "3      819\n",
       "4      470\n",
       "5      291\n",
       "6      181\n",
       "7       92\n",
       "8       74\n",
       "9       61\n",
       "12      26\n",
       "10      26\n",
       "11      22\n",
       "14      15\n",
       "13      13\n",
       "16       7\n",
       "19       6\n",
       "18       6\n",
       "15       4\n",
       "17       3\n",
       "33       2\n",
       "38       2\n",
       "24       2\n",
       "27       1\n",
       "35       1\n",
       "41       1\n",
       "20       1\n",
       "25       1\n",
       "69       1\n",
       "32       1\n",
       "23       1\n",
       "55       1\n",
       "Name: subject_in_context_count, dtype: int64"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['subject_in_context_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_json('enhanced_'+validation_dataset, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract position of answer regarding question subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_json('enhanced_'+validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_pieces(doc):\n",
    "    subjects = []\n",
    "    for ent in doc:\n",
    "        if ent.dep_ == 'nsubj':\n",
    "            subjects.append(ent.text)\n",
    "    return subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "def extract_answer_position_with_respect_to_subject(data):\n",
    "    q_subjects = []\n",
    "\n",
    "    for item in data['question']:\n",
    "        question = nlp(item)\n",
    "        q_subjects.append(doc_pieces(question))\n",
    "\n",
    "    positions = []\n",
    "\n",
    "    for context, q_sub, answer in zip(data['context'], q_subjects, data['answers']):\n",
    "        pos = 0\n",
    "        max = 0\n",
    "        for item in q_sub:\n",
    "            if item in context:\n",
    "                indexes = [m.start() for m in re.finditer(item, context)]\n",
    "                counter = 0\n",
    "                for index in indexes:\n",
    "                    if answer['answer_start'][0] < index:\n",
    "                        break\n",
    "                    else:\n",
    "                        counter += 1\n",
    "                if max < counter:\n",
    "                    max = counter\n",
    "                pos = max\n",
    "            else:\n",
    "                pos = -1\n",
    "        positions.append(pos)\n",
    "    \n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['answer_subject_positions'] = extract_answer_position_with_respect_to_subject(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['answer_sunjects'] = q_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0     3049\n",
       "-1     2995\n",
       " 1     2854\n",
       " 2      888\n",
       " 3      381\n",
       " 4      176\n",
       " 5       80\n",
       " 6       39\n",
       " 8       28\n",
       " 7       26\n",
       " 9       17\n",
       " 10      10\n",
       " 11       7\n",
       " 13       7\n",
       " 12       5\n",
       " 14       3\n",
       " 15       2\n",
       " 37       1\n",
       " 20       1\n",
       " 26       1\n",
       "Name: answer_subject_positions, dtype: int64"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['answer_subject_positions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0     3049\n",
       "-1     2995\n",
       " 1     2854\n",
       " 2      888\n",
       " 3      381\n",
       " 4      176\n",
       " 5       80\n",
       " 6       39\n",
       " 8       28\n",
       " 7       26\n",
       " 9       17\n",
       " 10      10\n",
       " 11       7\n",
       " 13       7\n",
       " 12       5\n",
       " 14       3\n",
       " 15       2\n",
       " 37       1\n",
       " 20       1\n",
       " 26       1\n",
       "Name: answer_subject_positions, dtype: int64"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['answer_subject_positions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data.answer_subject_positions >= 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_json(file_folder+'enhanced_'+validation_dataset, orient='records')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7a7a7019c9e0c1b9f0e0c3be70dc9924c7adf8b61dfc45d9a6a9f2f7a665204"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
